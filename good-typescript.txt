Script started on Thu Jul  4 21:47:48 2019
localhost(~): while true; do date; ssh ghawkins@jetsonnano.local ./performance-test; sleep 120; done
Thu Jul  4 21:47:56 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
CPUs set to performance
+ echo 'CPUs set to performance'
+ timeout 2s tegrastats
RAM 441/3965MB (lfb 715x4MB) CPU [1%@1428,24%@1428,31%@1428,19%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@31C CPU@34C iwlwifi@37C PMIC@100C GPU@33C AO@38.5C thermal@33.75C POM_5V_IN 1700/1700 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 244946ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 30.9382 ms.
Time taken for inference per run is 27.9101 ms.
Time taken for inference per run is 27.9058 ms.
Time taken for inference per run is 28.0184 ms.
Time taken for inference per run is 27.8966 ms.
Time taken for inference per run is 27.9017 ms.
Time taken for inference per run is 27.916 ms.
Time taken for inference per run is 27.9007 ms.
Time taken for inference per run is 27.8995 ms.
Time taken for inference per run is 27.8984 ms.
Average time spent per iteration is 28.2186 ms.
Time taken for inference is 27.8984 ms.
 KeepCount 100

real	4m37.721s
user	0m37.832s
sys	1m50.052s
+ timeout 2s tegrastats
RAM 885/3965MB (lfb 392x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@38C CPU@41.5C iwlwifi@37C PMIC@100C GPU@40C AO@46.5C thermal@40.5C POM_5V_IN 1661/1661 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 885/3965MB (lfb 392x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@37C CPU@40.5C iwlwifi@37C PMIC@100C GPU@39.5C AO@45C thermal@40C POM_5V_IN 1661/1661 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 202270ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.1654 ms.
Time taken for inference per run is 33.1357 ms.
Time taken for inference per run is 33.1159 ms.
Time taken for inference per run is 33.0791 ms.
Time taken for inference per run is 33.1375 ms.
Time taken for inference per run is 33.0591 ms.
Time taken for inference per run is 33.0075 ms.
Time taken for inference per run is 33.0971 ms.
Time taken for inference per run is 33.1131 ms.
Time taken for inference per run is 33.1718 ms.
Average time spent per iteration is 33.1082 ms.
Time taken for inference is 33.1718 ms.
 KeepCount 100

real	3m57.897s
user	0m38.208s
sys	1m49.120s
+ timeout 2s tegrastats
RAM 885/3965MB (lfb 388x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@41.5C CPU@44C iwlwifi@39C PMIC@100C GPU@43.5C AO@49C thermal@43.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 884/3965MB (lfb 388x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@40.5C CPU@43.5C iwlwifi@40C PMIC@100C GPU@42.5C AO@48C thermal@42.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195993ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3921 ms.
Time taken for inference per run is 26.4164 ms.
Time taken for inference per run is 26.385 ms.
Time taken for inference per run is 26.3292 ms.
Time taken for inference per run is 26.1557 ms.
Time taken for inference per run is 26.2612 ms.
Time taken for inference per run is 26.1872 ms.
Time taken for inference per run is 26.273 ms.
Time taken for inference per run is 26.1702 ms.
Time taken for inference per run is 26.2659 ms.
Average time spent per iteration is 26.2836 ms.
Time taken for inference is 26.2659 ms.
 KeepCount 100

real	3m44.860s
user	0m38.116s
sys	1m49.080s
+ timeout 2s tegrastats
RAM 885/3965MB (lfb 384x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@41C PMIC@100C GPU@46C AO@52.5C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 885/3965MB (lfb 384x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@41C PMIC@100C GPU@44C AO@50.5C thermal@44.75C POM_5V_IN 2149/2149 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188755ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0699 ms.
Time taken for inference per run is 26.0693 ms.
Time taken for inference per run is 26.0762 ms.
Time taken for inference per run is 26.071 ms.
Time taken for inference per run is 26.0689 ms.
Time taken for inference per run is 26.0702 ms.
Time taken for inference per run is 26.0743 ms.
Time taken for inference per run is 26.0689 ms.
Time taken for inference per run is 26.0682 ms.
Time taken for inference per run is 26.0716 ms.
Average time spent per iteration is 26.0708 ms.
Time taken for inference is 26.0716 ms.
 KeepCount 100

real	3m37.276s
user	0m36.408s
sys	1m43.660s
+ timeout 2s tegrastats
RAM 884/3965MB (lfb 383x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@41C PMIC@100C GPU@46.5C AO@54C thermal@47.75C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Thu Jul  4 22:10:12 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 808x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@41C CPU@43.5C iwlwifi@41C PMIC@100C GPU@45C AO@49C thermal@44.5C POM_5V_IN 1661/1661 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 246408ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.4727 ms.
Time taken for inference per run is 27.968 ms.
Time taken for inference per run is 27.8614 ms.
Time taken for inference per run is 27.965 ms.
Time taken for inference per run is 27.8638 ms.
Time taken for inference per run is 27.8645 ms.
Time taken for inference per run is 27.8875 ms.
Time taken for inference per run is 27.8906 ms.
Time taken for inference per run is 27.9813 ms.
Time taken for inference per run is 27.9348 ms.
Average time spent per iteration is 28.069 ms.
Time taken for inference is 27.9348 ms.
 KeepCount 100

real	4m39.018s
user	0m38.012s
sys	1m50.208s
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 483x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@41C PMIC@100C GPU@46C AO@52.5C thermal@46.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 483x4MB) CPU [0%@1428,1%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45C iwlwifi@41C PMIC@100C GPU@44.5C AO@50.5C thermal@44.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 209351ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 41.779 ms.
Time taken for inference per run is 41.7207 ms.
Time taken for inference per run is 41.7158 ms.
Time taken for inference per run is 41.7367 ms.
Time taken for inference per run is 41.7317 ms.
Time taken for inference per run is 41.7009 ms.
Time taken for inference per run is 41.6849 ms.
Time taken for inference per run is 41.6611 ms.
Time taken for inference per run is 41.6228 ms.
Time taken for inference per run is 41.7091 ms.
Average time spent per iteration is 41.7063 ms.
Time taken for inference is 41.7091 ms.
 KeepCount 100

real	4m13.649s
user	0m38.028s
sys	1m49.452s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@41C PMIC@100C GPU@46C AO@52C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 479x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45C iwlwifi@41C PMIC@100C GPU@44.5C AO@50.5C thermal@45.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197458ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3725 ms.
Time taken for inference per run is 26.1758 ms.
Time taken for inference per run is 26.3106 ms.
Time taken for inference per run is 26.1802 ms.
Time taken for inference per run is 26.1762 ms.
Time taken for inference per run is 26.1694 ms.
Time taken for inference per run is 26.2782 ms.
Time taken for inference per run is 26.2432 ms.
Time taken for inference per run is 26.2707 ms.
Time taken for inference per run is 26.2445 ms.
Average time spent per iteration is 26.2421 ms.
Time taken for inference is 26.2445 ms.
 KeepCount 100

real	3m46.220s
user	0m38.760s
sys	1m49.276s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@48.5C iwlwifi@42C PMIC@100C GPU@48C AO@54C thermal@48.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@42C PMIC@100C GPU@45C AO@52.5C thermal@46C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 189139ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0699 ms.
Time taken for inference per run is 26.0657 ms.
Time taken for inference per run is 26.07 ms.
Time taken for inference per run is 26.0662 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.0643 ms.
Time taken for inference per run is 26.0686 ms.
Time taken for inference per run is 26.0646 ms.
Time taken for inference per run is 26.0672 ms.
Time taken for inference per run is 26.063 ms.
Average time spent per iteration is 26.0666 ms.
Time taken for inference is 26.063 ms.
 KeepCount 100

real	3m37.645s
user	0m36.828s
sys	1m43.656s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48C AO@55.5C thermal@48.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 412/412
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Thu Jul  4 22:32:46 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 421/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 245935ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 30.888 ms.
Time taken for inference per run is 28.0023 ms.
Time taken for inference per run is 27.9483 ms.
Time taken for inference per run is 27.8951 ms.
Time taken for inference per run is 27.925 ms.
Time taken for inference per run is 27.9323 ms.
Time taken for inference per run is 27.9929 ms.
Time taken for inference per run is 28.03 ms.
Time taken for inference per run is 27.9137 ms.
Time taken for inference per run is 27.9972 ms.
Average time spent per iteration is 28.2525 ms.
Time taken for inference is 27.9972 ms.
 KeepCount 100

real	4m38.702s
user	0m38.204s
sys	1m49.456s
+ timeout 2s tegrastats
RAM 896/3965MB (lfb 466x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@46.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 896/3965MB (lfb 466x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@41C PMIC@100C GPU@46.5C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196219ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2829 ms.
Time taken for inference per run is 26.3864 ms.
Time taken for inference per run is 26.2433 ms.
Time taken for inference per run is 26.2861 ms.
Time taken for inference per run is 26.2882 ms.
Time taken for inference per run is 26.3609 ms.
Time taken for inference per run is 26.3131 ms.
Time taken for inference per run is 26.2913 ms.
Time taken for inference per run is 26.3276 ms.
Time taken for inference per run is 26.2214 ms.
Average time spent per iteration is 26.3001 ms.
Time taken for inference is 26.2214 ms.
 KeepCount 100

real	3m45.046s
user	0m38.576s
sys	1m48.904s
+ timeout 2s tegrastats
RAM 898/3965MB (lfb 461x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49C iwlwifi@42C PMIC@100C GPU@48C AO@54.5C thermal@48.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 898/3965MB (lfb 461x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47C iwlwifi@42C PMIC@100C GPU@47.5C AO@52.5C thermal@47.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196740ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3721 ms.
Time taken for inference per run is 26.2797 ms.
Time taken for inference per run is 26.1693 ms.
Time taken for inference per run is 26.2464 ms.
Time taken for inference per run is 26.2867 ms.
Time taken for inference per run is 26.1646 ms.
Time taken for inference per run is 26.1826 ms.
Time taken for inference per run is 26.2013 ms.
Time taken for inference per run is 26.2208 ms.
Time taken for inference per run is 26.1623 ms.
Average time spent per iteration is 26.2286 ms.
Time taken for inference is 26.1623 ms.
 KeepCount 100

real	3m45.572s
user	0m38.576s
sys	1m49.284s
+ timeout 2s tegrastats
RAM 898/3965MB (lfb 459x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 899/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@43C PMIC@100C GPU@46.5C AO@53.5C thermal@46.75C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188485ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0607 ms.
Time taken for inference per run is 26.0691 ms.
Time taken for inference per run is 26.0783 ms.
Time taken for inference per run is 26.0691 ms.
Time taken for inference per run is 26.0717 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.076 ms.
Time taken for inference per run is 26.0701 ms.
Time taken for inference per run is 26.0681 ms.
Time taken for inference per run is 26.0683 ms.
Average time spent per iteration is 26.0698 ms.
Time taken for inference is 26.0683 ms.
 KeepCount 100

real	3m36.996s
user	0m36.280s
sys	1m43.560s
+ timeout 2s tegrastats
RAM 898/3965MB (lfb 457x4MB) CPU [0%@1428,0%@1428,1%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48C AO@55.5C thermal@49C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 412/412
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Thu Jul  4 22:54:49 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 251371ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 31.9468 ms.
Time taken for inference per run is 29.7773 ms.
Time taken for inference per run is 29.6164 ms.
Time taken for inference per run is 29.6093 ms.
Time taken for inference per run is 29.6068 ms.
Time taken for inference per run is 29.5887 ms.
Time taken for inference per run is 29.6214 ms.
Time taken for inference per run is 29.6513 ms.
Time taken for inference per run is 29.6101 ms.
Time taken for inference per run is 29.6889 ms.
Average time spent per iteration is 29.8717 ms.
Time taken for inference is 29.6889 ms.
 KeepCount 100

real	4m45.851s
user	0m38.176s
sys	1m50.208s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@46.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 482x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@46C iwlwifi@41C PMIC@100C GPU@45C AO@51C thermal@45.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 225129ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 55.4495 ms.
Time taken for inference per run is 55.3468 ms.
Time taken for inference per run is 55.3826 ms.
Time taken for inference per run is 55.3996 ms.
Time taken for inference per run is 55.3468 ms.
Time taken for inference per run is 55.4047 ms.
Time taken for inference per run is 55.478 ms.
Time taken for inference per run is 55.4604 ms.
Time taken for inference per run is 55.4561 ms.
Time taken for inference per run is 55.3133 ms.
Average time spent per iteration is 55.4038 ms.
Time taken for inference is 55.3133 ms.
 KeepCount 100

real	4m43.040s
user	0m38.416s
sys	1m49.532s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@41C PMIC@100C GPU@46C AO@51.5C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@41C PMIC@100C GPU@44.5C AO@50.5C thermal@44.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196076ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3801 ms.
Time taken for inference per run is 26.3705 ms.
Time taken for inference per run is 26.2479 ms.
Time taken for inference per run is 26.167 ms.
Time taken for inference per run is 26.1807 ms.
Time taken for inference per run is 26.3686 ms.
Time taken for inference per run is 26.3265 ms.
Time taken for inference per run is 26.1686 ms.
Time taken for inference per run is 26.1909 ms.
Time taken for inference per run is 26.2495 ms.
Average time spent per iteration is 26.265 ms.
Time taken for inference is 26.2495 ms.
 KeepCount 100

real	3m44.904s
user	0m38.192s
sys	1m49.400s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@48.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 475x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@44.5C AO@52C thermal@45.75C POM_5V_IN 2149/2149 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188491ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0498 ms.
Time taken for inference per run is 26.0754 ms.
Time taken for inference per run is 26.071 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.0695 ms.
Time taken for inference per run is 26.0676 ms.
Time taken for inference per run is 26.0654 ms.
Time taken for inference per run is 26.0686 ms.
Time taken for inference per run is 26.064 ms.
Time taken for inference per run is 26.0723 ms.
Average time spent per iteration is 26.067 ms.
Time taken for inference is 26.0723 ms.
 KeepCount 100

real	3m37.003s
user	0m36.008s
sys	1m43.812s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 469x4MB) CPU [2%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49C iwlwifi@43C PMIC@100C GPU@47.5C AO@55C thermal@48.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Thu Jul  4 23:17:57 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 420/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@41.5C CPU@44.5C iwlwifi@42C PMIC@100C GPU@45.5C AO@49.5C thermal@45C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 250444ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 30.6746 ms.
Time taken for inference per run is 27.9561 ms.
Time taken for inference per run is 27.9141 ms.
Time taken for inference per run is 27.9088 ms.
Time taken for inference per run is 27.9033 ms.
Time taken for inference per run is 27.9019 ms.
Time taken for inference per run is 27.912 ms.
Time taken for inference per run is 27.9054 ms.
Time taken for inference per run is 27.8919 ms.
Time taken for inference per run is 27.9979 ms.
Average time spent per iteration is 28.1966 ms.
Time taken for inference is 27.9979 ms.
 KeepCount 100

real	4m43.298s
user	0m38.364s
sys	1m49.580s
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@41C PMIC@100C GPU@46C AO@52.5C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45C iwlwifi@41C PMIC@100C GPU@45C AO@51C thermal@45C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 202473ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.1186 ms.
Time taken for inference per run is 33.1393 ms.
Time taken for inference per run is 33.1347 ms.
Time taken for inference per run is 33.0603 ms.
Time taken for inference per run is 33.0968 ms.
Time taken for inference per run is 33.0033 ms.
Time taken for inference per run is 32.9924 ms.
Time taken for inference per run is 32.9937 ms.
Time taken for inference per run is 32.9981 ms.
Time taken for inference per run is 33.0727 ms.
Average time spent per iteration is 33.061 ms.
Time taken for inference is 33.0727 ms.
 KeepCount 100

real	3m58.108s
user	0m38.500s
sys	1m48.872s
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@41C PMIC@100C GPU@46C AO@53C thermal@46.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@41C PMIC@100C GPU@45.5C AO@51C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196997ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.221 ms.
Time taken for inference per run is 26.3195 ms.
Time taken for inference per run is 26.2259 ms.
Time taken for inference per run is 26.3867 ms.
Time taken for inference per run is 26.3875 ms.
Time taken for inference per run is 26.3201 ms.
Time taken for inference per run is 26.277 ms.
Time taken for inference per run is 26.383 ms.
Time taken for inference per run is 26.1674 ms.
Time taken for inference per run is 26.2076 ms.
Average time spent per iteration is 26.2896 ms.
Time taken for inference is 26.2076 ms.
 KeepCount 100

real	3m45.769s
user	0m38.372s
sys	1m49.408s
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@48.5C iwlwifi@42C PMIC@100C GPU@48C AO@54C thermal@48.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@45.5C AO@52C thermal@46.25C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 189206ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0532 ms.
Time taken for inference per run is 26.0737 ms.
Time taken for inference per run is 26.0764 ms.
Time taken for inference per run is 26.0747 ms.
Time taken for inference per run is 26.0734 ms.
Time taken for inference per run is 26.064 ms.
Time taken for inference per run is 26.0762 ms.
Time taken for inference per run is 26.07 ms.
Time taken for inference per run is 26.0728 ms.
Time taken for inference per run is 26.0715 ms.
Average time spent per iteration is 26.0706 ms.
Time taken for inference is 26.0715 ms.
 KeepCount 100

real	3m37.706s
user	0m36.260s
sys	1m44.064s
+ timeout 2s tegrastats
RAM 864/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@49.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@55C thermal@48.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Thu Jul  4 23:40:20 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 809x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@41.5C CPU@44.5C iwlwifi@42C PMIC@100C GPU@45.5C AO@49.5C thermal@45C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247074ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.2882 ms.
Time taken for inference per run is 28.0437 ms.
Time taken for inference per run is 28.0369 ms.
Time taken for inference per run is 27.9682 ms.
Time taken for inference per run is 27.8714 ms.
Time taken for inference per run is 27.8738 ms.
Time taken for inference per run is 27.8909 ms.
Time taken for inference per run is 27.8813 ms.
Time taken for inference per run is 27.8838 ms.
Time taken for inference per run is 27.9882 ms.
Average time spent per iteration is 28.0726 ms.
Time taken for inference is 27.9882 ms.
 KeepCount 100

real	4m39.684s
user	0m37.672s
sys	1m50.228s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 474x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@41C PMIC@100C GPU@46C AO@52.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@45.5C iwlwifi@41C PMIC@100C GPU@45C AO@50.5C thermal@45.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 224741ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 55.4204 ms.
Time taken for inference per run is 55.4996 ms.
Time taken for inference per run is 55.4286 ms.
Time taken for inference per run is 55.3239 ms.
Time taken for inference per run is 55.3452 ms.
Time taken for inference per run is 55.3606 ms.
Time taken for inference per run is 55.4186 ms.
Time taken for inference per run is 55.3589 ms.
Time taken for inference per run is 55.3144 ms.
Time taken for inference per run is 55.416 ms.
Average time spent per iteration is 55.3886 ms.
Time taken for inference is 55.416 ms.
 KeepCount 100

real	4m42.692s
user	0m38.608s
sys	1m48.968s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 468x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@41C PMIC@100C GPU@45C AO@51.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 468x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@44.5C iwlwifi@41C PMIC@100C GPU@44C AO@50C thermal@44.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196208ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2015 ms.
Time taken for inference per run is 26.2663 ms.
Time taken for inference per run is 26.2704 ms.
Time taken for inference per run is 26.4078 ms.
Time taken for inference per run is 26.2078 ms.
Time taken for inference per run is 26.1792 ms.
Time taken for inference per run is 26.2138 ms.
Time taken for inference per run is 26.1769 ms.
Time taken for inference per run is 26.24 ms.
Time taken for inference per run is 26.1689 ms.
Average time spent per iteration is 26.2332 ms.
Time taken for inference is 26.1689 ms.
 KeepCount 100

real	3m44.940s
user	0m37.952s
sys	1m49.384s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 463x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@48.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 464x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@41C PMIC@100C GPU@45.5C AO@52C thermal@46C POM_5V_IN 2153/2153 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188616ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0716 ms.
Time taken for inference per run is 26.0776 ms.
Time taken for inference per run is 26.0702 ms.
Time taken for inference per run is 26.0948 ms.
Time taken for inference per run is 26.0703 ms.
Time taken for inference per run is 26.072 ms.
Time taken for inference per run is 26.0674 ms.
Time taken for inference per run is 26.0721 ms.
Time taken for inference per run is 26.0665 ms.
Time taken for inference per run is 26.0719 ms.
Average time spent per iteration is 26.0734 ms.
Time taken for inference is 26.0719 ms.
 KeepCount 100

real	3m37.115s
user	0m36.384s
sys	1m43.680s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 459x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49C iwlwifi@42C PMIC@100C GPU@47.5C AO@55C thermal@48.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 00:03:21 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
CPUs set to performance
+ echo 'CPUs set to performance'
+ timeout 2s tegrastats
RAM 423/3965MB (lfb 817x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@44C iwlwifi@42C PMIC@100C GPU@45.5C AO@50C thermal@45C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 245288ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 30.7391 ms.
Time taken for inference per run is 27.8634 ms.
Time taken for inference per run is 27.8855 ms.
Time taken for inference per run is 27.8694 ms.
Time taken for inference per run is 27.8663 ms.
Time taken for inference per run is 27.9483 ms.
Time taken for inference per run is 28.0213 ms.
Time taken for inference per run is 27.9278 ms.
Time taken for inference per run is 28.0331 ms.
Time taken for inference per run is 27.9143 ms.
Average time spent per iteration is 28.2069 ms.
Time taken for inference is 27.9143 ms.
 KeepCount 100

real	4m38.146s
user	0m37.920s
sys	1m50.088s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@41C PMIC@100C GPU@46.5C AO@53C thermal@46.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@41C PMIC@100C GPU@46C AO@51C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196131ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2988 ms.
Time taken for inference per run is 26.3462 ms.
Time taken for inference per run is 26.3359 ms.
Time taken for inference per run is 26.2845 ms.
Time taken for inference per run is 26.2974 ms.
Time taken for inference per run is 26.224 ms.
Time taken for inference per run is 26.2848 ms.
Time taken for inference per run is 26.3541 ms.
Time taken for inference per run is 26.3468 ms.
Time taken for inference per run is 26.2441 ms.
Average time spent per iteration is 26.3016 ms.
Time taken for inference is 26.2441 ms.
 KeepCount 100

real	3m45.027s
user	0m38.436s
sys	1m49.356s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 466x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@48.5C AO@54.5C thermal@48.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 466x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47C iwlwifi@42C PMIC@100C GPU@47.5C AO@53C thermal@47.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196055ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3231 ms.
Time taken for inference per run is 26.2435 ms.
Time taken for inference per run is 26.1864 ms.
Time taken for inference per run is 26.3056 ms.
Time taken for inference per run is 26.347 ms.
Time taken for inference per run is 26.2278 ms.
Time taken for inference per run is 26.2005 ms.
Time taken for inference per run is 26.2841 ms.
Time taken for inference per run is 26.3296 ms.
Time taken for inference per run is 26.2598 ms.
Average time spent per iteration is 26.2707 ms.
Time taken for inference is 26.2598 ms.
 KeepCount 100

real	3m44.914s
user	0m38.736s
sys	1m48.980s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 463x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 463x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48C iwlwifi@43C PMIC@100C GPU@46C AO@53.5C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188387ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0688 ms.
Time taken for inference per run is 26.0681 ms.
Time taken for inference per run is 26.0731 ms.
Time taken for inference per run is 26.0646 ms.
Time taken for inference per run is 26.0629 ms.
Time taken for inference per run is 26.0561 ms.
Time taken for inference per run is 26.0585 ms.
Time taken for inference per run is 26.0567 ms.
Time taken for inference per run is 26.0556 ms.
Time taken for inference per run is 26.0562 ms.
Average time spent per iteration is 26.0621 ms.
Time taken for inference is 26.0562 ms.
 KeepCount 100

real	3m36.881s
user	0m35.780s
sys	1m44.028s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 462x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@48C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 00:25:24 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 246961ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 31.2879 ms.
Time taken for inference per run is 29.7812 ms.
Time taken for inference per run is 29.6249 ms.
Time taken for inference per run is 29.5823 ms.
Time taken for inference per run is 29.6373 ms.
Time taken for inference per run is 29.6536 ms.
Time taken for inference per run is 29.5857 ms.
Time taken for inference per run is 29.5822 ms.
Time taken for inference per run is 29.6467 ms.
Time taken for inference per run is 29.5916 ms.
Average time spent per iteration is 29.7973 ms.
Time taken for inference is 29.5916 ms.
 KeepCount 100

real	4m41.301s
user	0m37.904s
sys	1m50.144s
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@42C PMIC@100C GPU@47C AO@53.5C thermal@47C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 477x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46C iwlwifi@42C PMIC@100C GPU@45.5C AO@52C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 205094ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 36.6251 ms.
Time taken for inference per run is 36.5682 ms.
Time taken for inference per run is 36.5092 ms.
Time taken for inference per run is 36.5092 ms.
Time taken for inference per run is 36.584 ms.
Time taken for inference per run is 36.5163 ms.
Time taken for inference per run is 36.4896 ms.
Time taken for inference per run is 36.4993 ms.
Time taken for inference per run is 36.5115 ms.
Time taken for inference per run is 36.5312 ms.
Average time spent per iteration is 36.5344 ms.
Time taken for inference is 36.5312 ms.
 KeepCount 100

real	4m4.146s
user	0m38.128s
sys	1m49.232s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@42C PMIC@100C GPU@47C AO@53C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 474x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@52C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196636ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3034 ms.
Time taken for inference per run is 26.1586 ms.
Time taken for inference per run is 26.1939 ms.
Time taken for inference per run is 26.1607 ms.
Time taken for inference per run is 26.2866 ms.
Time taken for inference per run is 26.3674 ms.
Time taken for inference per run is 26.3759 ms.
Time taken for inference per run is 26.311 ms.
Time taken for inference per run is 26.2548 ms.
Time taken for inference per run is 26.161 ms.
Average time spent per iteration is 26.2573 ms.
Time taken for inference is 26.161 ms.
 KeepCount 100

real	3m45.409s
user	0m38.316s
sys	1m49.440s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@43C PMIC@100C GPU@46C AO@53C thermal@46.75C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188846ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0679 ms.
Time taken for inference per run is 26.0713 ms.
Time taken for inference per run is 26.0659 ms.
Time taken for inference per run is 26.0689 ms.
Time taken for inference per run is 26.0646 ms.
Time taken for inference per run is 26.0755 ms.
Time taken for inference per run is 26.0672 ms.
Time taken for inference per run is 26.0679 ms.
Time taken for inference per run is 26.0663 ms.
Time taken for inference per run is 26.0725 ms.
Average time spent per iteration is 26.0688 ms.
Time taken for inference is 26.0725 ms.
 KeepCount 100

real	3m37.360s
user	0m36.384s
sys	1m43.924s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 00:47:49 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
+ echo performance
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 420/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247131ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.7547 ms.
Time taken for inference per run is 28.1342 ms.
Time taken for inference per run is 27.8979 ms.
Time taken for inference per run is 27.866 ms.
Time taken for inference per run is 28.0171 ms.
Time taken for inference per run is 27.9135 ms.
Time taken for inference per run is 28.0035 ms.
Time taken for inference per run is 27.867 ms.
Time taken for inference per run is 27.8917 ms.
Time taken for inference per run is 27.9938 ms.
Average time spent per iteration is 28.1339 ms.
Time taken for inference is 27.9938 ms.
 KeepCount 100

real	4m39.756s
user	0m38.340s
sys	1m49.532s
+ timeout 2s tegrastats
RAM 863/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@42C PMIC@100C GPU@47C AO@53C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 863/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 201092ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.0057 ms.
Time taken for inference per run is 33.1229 ms.
Time taken for inference per run is 33.0462 ms.
Time taken for inference per run is 33.0792 ms.
Time taken for inference per run is 33.0258 ms.
Time taken for inference per run is 33.0405 ms.
Time taken for inference per run is 33.0397 ms.
Time taken for inference per run is 33.069 ms.
Time taken for inference per run is 33.0306 ms.
Time taken for inference per run is 33.0337 ms.
Average time spent per iteration is 33.0493 ms.
Time taken for inference is 33.0337 ms.
 KeepCount 100

real	3m56.635s
user	0m37.876s
sys	1m49.316s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@42C PMIC@100C GPU@47C AO@53.5C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46C iwlwifi@42C PMIC@100C GPU@46.5C AO@52C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196618ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2783 ms.
Time taken for inference per run is 26.2444 ms.
Time taken for inference per run is 26.1951 ms.
Time taken for inference per run is 26.3224 ms.
Time taken for inference per run is 26.279 ms.
Time taken for inference per run is 26.1846 ms.
Time taken for inference per run is 26.2531 ms.
Time taken for inference per run is 26.1689 ms.
Time taken for inference per run is 26.3378 ms.
Time taken for inference per run is 26.1821 ms.
Average time spent per iteration is 26.2446 ms.
Time taken for inference is 26.1821 ms.
 KeepCount 100

real	3m45.391s
user	0m38.440s
sys	1m49.312s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 470x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@49.5C iwlwifi@43C PMIC@100C GPU@49C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 470x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46.5C AO@53C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188678ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0652 ms.
Time taken for inference per run is 26.072 ms.
Time taken for inference per run is 26.0675 ms.
Time taken for inference per run is 26.0616 ms.
Time taken for inference per run is 26.0623 ms.
Time taken for inference per run is 26.0675 ms.
Time taken for inference per run is 26.0651 ms.
Time taken for inference per run is 26.0555 ms.
Time taken for inference per run is 26.0617 ms.
Time taken for inference per run is 26.0591 ms.
Average time spent per iteration is 26.0638 ms.
Time taken for inference is 26.0591 ms.
 KeepCount 100

real	3m37.181s
user	0m36.384s
sys	1m43.620s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 01:10:06 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
nvhost_podgov
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
CPUs set to performance
+ echo 'CPUs set to performance'
+ timeout 2s tegrastats
RAM 424/3965MB (lfb 808x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247619ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.8479 ms.
Time taken for inference per run is 27.8877 ms.
Time taken for inference per run is 27.9903 ms.
Time taken for inference per run is 27.9724 ms.
Time taken for inference per run is 27.9272 ms.
Time taken for inference per run is 27.8689 ms.
Time taken for inference per run is 27.8599 ms.
Time taken for inference per run is 27.8589 ms.
Time taken for inference per run is 27.8514 ms.
Time taken for inference per run is 27.8699 ms.
Average time spent per iteration is 27.9934 ms.
Time taken for inference is 27.8699 ms.
 KeepCount 100

real	4m40.131s
user	0m38.148s
sys	1m49.396s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 486x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 486x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197014ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.0464 ms.
Time taken for inference per run is 27.9852 ms.
Time taken for inference per run is 28.013 ms.
Time taken for inference per run is 27.8918 ms.
Time taken for inference per run is 27.99 ms.
Time taken for inference per run is 27.9428 ms.
Time taken for inference per run is 27.9604 ms.
Time taken for inference per run is 27.967 ms.
Time taken for inference per run is 27.943 ms.
Time taken for inference per run is 27.9796 ms.
Average time spent per iteration is 27.9719 ms.
Time taken for inference is 27.9796 ms.
 KeepCount 100

real	3m47.565s
user	0m38.276s
sys	1m49.208s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48C AO@54.5C thermal@48.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@52.5C thermal@47.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197003ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3881 ms.
Time taken for inference per run is 26.3576 ms.
Time taken for inference per run is 26.3564 ms.
Time taken for inference per run is 26.2387 ms.
Time taken for inference per run is 26.1608 ms.
Time taken for inference per run is 26.2758 ms.
Time taken for inference per run is 26.1686 ms.
Time taken for inference per run is 26.1921 ms.
Time taken for inference per run is 26.246 ms.
Time taken for inference per run is 26.1842 ms.
Average time spent per iteration is 26.2568 ms.
Time taken for inference is 26.1842 ms.
 KeepCount 100

real	3m45.736s
user	0m38.704s
sys	1m49.232s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@47C AO@53.5C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188881ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0684 ms.
Time taken for inference per run is 26.0624 ms.
Time taken for inference per run is 26.0627 ms.
Time taken for inference per run is 26.062 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.061 ms.
Time taken for inference per run is 26.0639 ms.
Time taken for inference per run is 26.0645 ms.
Time taken for inference per run is 26.0658 ms.
Time taken for inference per run is 26.0623 ms.
Average time spent per iteration is 26.064 ms.
Time taken for inference is 26.0623 ms.
 KeepCount 100

real	3m37.397s
user	0m35.984s
sys	1m44.288s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 472x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@48C CPU@50.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 01:32:14 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 420/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@46C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247010ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 37.4712 ms.
Time taken for inference per run is 31.4208 ms.
Time taken for inference per run is 31.2955 ms.
Time taken for inference per run is 31.295 ms.
Time taken for inference per run is 31.3019 ms.
Time taken for inference per run is 31.4075 ms.
Time taken for inference per run is 31.3218 ms.
Time taken for inference per run is 31.3192 ms.
Time taken for inference per run is 31.331 ms.
Time taken for inference per run is 31.3333 ms.
Average time spent per iteration is 31.9497 ms.
Time taken for inference is 31.3333 ms.
 KeepCount 100

real	4m43.600s
user	0m38.492s
sys	1m49.420s
+ timeout 2s tegrastats
RAM 863/3965MB (lfb 486x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@42C PMIC@100C GPU@47C AO@53.5C thermal@47.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 863/3965MB (lfb 486x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 215285ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 46.9398 ms.
Time taken for inference per run is 46.8103 ms.
Time taken for inference per run is 46.7366 ms.
Time taken for inference per run is 46.7409 ms.
Time taken for inference per run is 46.7384 ms.
Time taken for inference per run is 46.8703 ms.
Time taken for inference per run is 46.7326 ms.
Time taken for inference per run is 46.893 ms.
Time taken for inference per run is 46.8333 ms.
Time taken for inference per run is 46.7519 ms.
Average time spent per iteration is 46.8047 ms.
Time taken for inference is 46.7519 ms.
 KeepCount 100

real	4m24.606s
user	0m38.168s
sys	1m49.156s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46C AO@52.5C thermal@46C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@45C AO@50.5C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195316ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2868 ms.
Time taken for inference per run is 26.1525 ms.
Time taken for inference per run is 26.1689 ms.
Time taken for inference per run is 26.1862 ms.
Time taken for inference per run is 26.1566 ms.
Time taken for inference per run is 26.1526 ms.
Time taken for inference per run is 26.152 ms.
Time taken for inference per run is 26.1555 ms.
Time taken for inference per run is 26.1529 ms.
Time taken for inference per run is 26.1499 ms.
Average time spent per iteration is 26.1714 ms.
Time taken for inference is 26.1499 ms.
 KeepCount 100

real	3m43.989s
user	0m37.788s
sys	1m49.416s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49.5C iwlwifi@42C PMIC@100C GPU@48C AO@54.5C thermal@48.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47.5C iwlwifi@42C PMIC@100C GPU@45.5C AO@53C thermal@46.5C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188663ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0721 ms.
Time taken for inference per run is 26.0804 ms.
Time taken for inference per run is 26.0742 ms.
Time taken for inference per run is 26.0743 ms.
Time taken for inference per run is 26.0733 ms.
Time taken for inference per run is 26.0769 ms.
Time taken for inference per run is 26.0765 ms.
Time taken for inference per run is 26.0777 ms.
Time taken for inference per run is 26.0755 ms.
Time taken for inference per run is 26.0772 ms.
Average time spent per iteration is 26.0758 ms.
Time taken for inference is 26.0772 ms.
 KeepCount 100

real	3m37.161s
user	0m36.408s
sys	1m43.636s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@48C AO@55.5C thermal@49.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 01:55:01 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
CPUs set to performance
+ echo 'CPUs set to performance'
+ timeout 2s tegrastats
RAM 423/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 248130ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.952 ms.
Time taken for inference per run is 27.9888 ms.
Time taken for inference per run is 28.1028 ms.
Time taken for inference per run is 28.0352 ms.
Time taken for inference per run is 28.0277 ms.
Time taken for inference per run is 27.9228 ms.
Time taken for inference per run is 27.9415 ms.
Time taken for inference per run is 27.9086 ms.
Time taken for inference per run is 28.0543 ms.
Time taken for inference per run is 28.097 ms.
Average time spent per iteration is 28.1031 ms.
Time taken for inference is 28.097 ms.
 KeepCount 100

real	4m40.759s
user	0m37.580s
sys	1m50.044s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 199594ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.6679 ms.
Time taken for inference per run is 29.6521 ms.
Time taken for inference per run is 29.6032 ms.
Time taken for inference per run is 29.5773 ms.
Time taken for inference per run is 29.5679 ms.
Time taken for inference per run is 29.5633 ms.
Time taken for inference per run is 29.5983 ms.
Time taken for inference per run is 29.6396 ms.
Time taken for inference per run is 29.7458 ms.
Time taken for inference per run is 29.7086 ms.
Average time spent per iteration is 29.6324 ms.
Time taken for inference is 29.7086 ms.
 KeepCount 100

real	3m51.741s
user	0m38.220s
sys	1m49.124s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47C AO@54C thermal@47.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@52C thermal@46.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197146ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3661 ms.
Time taken for inference per run is 26.3122 ms.
Time taken for inference per run is 26.2003 ms.
Time taken for inference per run is 26.345 ms.
Time taken for inference per run is 26.3308 ms.
Time taken for inference per run is 26.293 ms.
Time taken for inference per run is 26.3297 ms.
Time taken for inference per run is 26.4274 ms.
Time taken for inference per run is 26.3544 ms.
Time taken for inference per run is 26.2843 ms.
Average time spent per iteration is 26.3243 ms.
Time taken for inference is 26.2843 ms.
 KeepCount 100

real	3m45.946s
user	0m38.296s
sys	1m49.348s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 472x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 472x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46C AO@53C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188961ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0515 ms.
Time taken for inference per run is 26.0718 ms.
Time taken for inference per run is 26.0735 ms.
Time taken for inference per run is 26.0698 ms.
Time taken for inference per run is 26.0708 ms.
Time taken for inference per run is 26.0671 ms.
Time taken for inference per run is 26.0661 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.0672 ms.
Time taken for inference per run is 26.069 ms.
Average time spent per iteration is 26.0674 ms.
Time taken for inference is 26.069 ms.
 KeepCount 100

real	3m37.462s
user	0m36.440s
sys	1m43.888s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 470x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 02:17:14 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 428/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 250373ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.3312 ms.
Time taken for inference per run is 27.9549 ms.
Time taken for inference per run is 27.8867 ms.
Time taken for inference per run is 27.8705 ms.
Time taken for inference per run is 27.9298 ms.
Time taken for inference per run is 27.949 ms.
Time taken for inference per run is 27.8848 ms.
Time taken for inference per run is 27.9575 ms.
Time taken for inference per run is 27.8875 ms.
Time taken for inference per run is 27.9303 ms.
Average time spent per iteration is 28.0582 ms.
Time taken for inference is 27.9303 ms.
 KeepCount 100

real	4m43.028s
user	0m37.960s
sys	1m49.956s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 199760ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.777 ms.
Time taken for inference per run is 29.6534 ms.
Time taken for inference per run is 29.7272 ms.
Time taken for inference per run is 29.8441 ms.
Time taken for inference per run is 29.8501 ms.
Time taken for inference per run is 30.1192 ms.
Time taken for inference per run is 30.1976 ms.
Time taken for inference per run is 30.4996 ms.
Time taken for inference per run is 30.6673 ms.
Time taken for inference per run is 30.4397 ms.
Average time spent per iteration is 30.0775 ms.
Time taken for inference is 30.4397 ms.
 KeepCount 100

real	3m52.418s
user	0m38.436s
sys	1m49.112s
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@47.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@52C thermal@46.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197137ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.4028 ms.
Time taken for inference per run is 26.3668 ms.
Time taken for inference per run is 26.3469 ms.
Time taken for inference per run is 26.235 ms.
Time taken for inference per run is 26.1671 ms.
Time taken for inference per run is 26.1675 ms.
Time taken for inference per run is 26.1734 ms.
Time taken for inference per run is 26.3241 ms.
Time taken for inference per run is 26.3572 ms.
Time taken for inference per run is 26.2796 ms.
Average time spent per iteration is 26.282 ms.
Time taken for inference is 26.2796 ms.
 KeepCount 100

real	3m45.929s
user	0m38.252s
sys	1m49.460s
+ timeout 2s tegrastats
RAM 876/3965MB (lfb 472x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 876/3965MB (lfb 472x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46C AO@53C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188669ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0624 ms.
Time taken for inference per run is 26.069 ms.
Time taken for inference per run is 26.0629 ms.
Time taken for inference per run is 26.0642 ms.
Time taken for inference per run is 26.0643 ms.
Time taken for inference per run is 26.0669 ms.
Time taken for inference per run is 26.0668 ms.
Time taken for inference per run is 26.0623 ms.
Time taken for inference per run is 26.0636 ms.
Time taken for inference per run is 26.062 ms.
Average time spent per iteration is 26.0644 ms.
Time taken for inference is 26.062 ms.
 KeepCount 100

real	3m37.169s
user	0m36.344s
sys	1m43.768s
+ timeout 2s tegrastats
RAM 876/3965MB (lfb 470x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 02:39:30 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 248817ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.2739 ms.
Time taken for inference per run is 27.9238 ms.
Time taken for inference per run is 28.1189 ms.
Time taken for inference per run is 28.0561 ms.
Time taken for inference per run is 27.9018 ms.
Time taken for inference per run is 28.0265 ms.
Time taken for inference per run is 27.8747 ms.
Time taken for inference per run is 27.9414 ms.
Time taken for inference per run is 27.8599 ms.
Time taken for inference per run is 27.8744 ms.
Average time spent per iteration is 28.0851 ms.
Time taken for inference is 27.8744 ms.
 KeepCount 100

real	4m41.499s
user	0m38.752s
sys	1m49.288s
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 462x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53.5C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 462x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46.5C AO@51.5C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195371ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2009 ms.
Time taken for inference per run is 26.3518 ms.
Time taken for inference per run is 26.3181 ms.
Time taken for inference per run is 26.318 ms.
Time taken for inference per run is 26.2874 ms.
Time taken for inference per run is 26.3197 ms.
Time taken for inference per run is 26.3345 ms.
Time taken for inference per run is 26.2579 ms.
Time taken for inference per run is 26.2991 ms.
Time taken for inference per run is 26.3149 ms.
Average time spent per iteration is 26.3002 ms.
Time taken for inference is 26.3149 ms.
 KeepCount 100

real	3m44.267s
user	0m38.236s
sys	1m49.512s
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 459x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49.5C iwlwifi@42C PMIC@100C GPU@48C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 459x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@43C PMIC@100C GPU@48C AO@53C thermal@48C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196988ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2618 ms.
Time taken for inference per run is 26.3268 ms.
Time taken for inference per run is 26.2277 ms.
Time taken for inference per run is 26.2868 ms.
Time taken for inference per run is 26.2521 ms.
Time taken for inference per run is 26.266 ms.
Time taken for inference per run is 26.2412 ms.
Time taken for inference per run is 26.2983 ms.
Time taken for inference per run is 26.2877 ms.
Time taken for inference per run is 26.2323 ms.
Average time spent per iteration is 26.2681 ms.
Time taken for inference is 26.2323 ms.
 KeepCount 100

real	3m45.769s
user	0m38.488s
sys	1m49.304s
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@49C AO@55C thermal@50C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@47C AO@54C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188877ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0393 ms.
Time taken for inference per run is 26.0715 ms.
Time taken for inference per run is 26.0653 ms.
Time taken for inference per run is 26.0617 ms.
Time taken for inference per run is 26.063 ms.
Time taken for inference per run is 26.069 ms.
Time taken for inference per run is 26.064 ms.
Time taken for inference per run is 26.0611 ms.
Time taken for inference per run is 26.0632 ms.
Time taken for inference per run is 26.0679 ms.
Average time spent per iteration is 26.0626 ms.
Time taken for inference is 26.0679 ms.
 KeepCount 100

real	3m37.371s
user	0m36.232s
sys	1m43.992s
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 457x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 03:01:36 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 423/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 249776ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.6602 ms.
Time taken for inference per run is 27.9764 ms.
Time taken for inference per run is 28.0515 ms.
Time taken for inference per run is 27.9466 ms.
Time taken for inference per run is 27.9487 ms.
Time taken for inference per run is 27.9104 ms.
Time taken for inference per run is 27.9991 ms.
Time taken for inference per run is 28.0027 ms.
Time taken for inference per run is 28.0052 ms.
Time taken for inference per run is 27.9075 ms.
Average time spent per iteration is 28.0408 ms.
Time taken for inference is 27.9075 ms.
 KeepCount 100

real	4m42.362s
user	0m38.324s
sys	1m50.160s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46.5C AO@51C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196212ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3776 ms.
Time taken for inference per run is 26.3595 ms.
Time taken for inference per run is 26.3387 ms.
Time taken for inference per run is 26.2772 ms.
Time taken for inference per run is 26.2049 ms.
Time taken for inference per run is 26.1779 ms.
Time taken for inference per run is 26.1834 ms.
Time taken for inference per run is 26.2239 ms.
Time taken for inference per run is 26.1776 ms.
Time taken for inference per run is 26.1868 ms.
Average time spent per iteration is 26.2507 ms.
Time taken for inference is 26.1868 ms.
 KeepCount 100

real	3m44.995s
user	0m38.676s
sys	1m48.720s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@43C PMIC@100C GPU@48C AO@52.5C thermal@47.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196265ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3414 ms.
Time taken for inference per run is 26.4235 ms.
Time taken for inference per run is 26.1763 ms.
Time taken for inference per run is 26.1971 ms.
Time taken for inference per run is 26.2307 ms.
Time taken for inference per run is 26.1548 ms.
Time taken for inference per run is 26.2767 ms.
Time taken for inference per run is 26.2064 ms.
Time taken for inference per run is 26.2957 ms.
Time taken for inference per run is 26.1539 ms.
Average time spent per iteration is 26.2457 ms.
Time taken for inference is 26.1539 ms.
 KeepCount 100

real	3m45.032s
user	0m37.684s
sys	1m49.620s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@43C PMIC@100C GPU@47C AO@53.5C thermal@47.5C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188577ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0649 ms.
Time taken for inference per run is 26.067 ms.
Time taken for inference per run is 26.0646 ms.
Time taken for inference per run is 26.062 ms.
Time taken for inference per run is 26.0534 ms.
Time taken for inference per run is 26.0638 ms.
Time taken for inference per run is 26.0607 ms.
Time taken for inference per run is 26.0645 ms.
Time taken for inference per run is 26.0573 ms.
Time taken for inference per run is 26.0602 ms.
Average time spent per iteration is 26.0618 ms.
Time taken for inference is 26.0602 ms.
 KeepCount 100

real	3m37.082s
user	0m36.200s
sys	1m43.672s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 466x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@56C thermal@50C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 03:23:43 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
CPUs set to performance
+ echo 'CPUs set to performance'
+ timeout 2s tegrastats
RAM 419/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@43C PMIC@100C GPU@46.5C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 246477ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.1628 ms.
Time taken for inference per run is 27.9089 ms.
Time taken for inference per run is 27.878 ms.
Time taken for inference per run is 27.8697 ms.
Time taken for inference per run is 27.8674 ms.
Time taken for inference per run is 27.8701 ms.
Time taken for inference per run is 27.8729 ms.
Time taken for inference per run is 27.8728 ms.
Time taken for inference per run is 27.8708 ms.
Time taken for inference per run is 27.8785 ms.
Average time spent per iteration is 28.0052 ms.
Time taken for inference is 27.8785 ms.
 KeepCount 100

real	4m39.035s
user	0m38.868s
sys	1m49.740s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 480x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@42C PMIC@100C GPU@47C AO@53C thermal@47.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 480x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@51C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 199440ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.7323 ms.
Time taken for inference per run is 29.6755 ms.
Time taken for inference per run is 29.6505 ms.
Time taken for inference per run is 29.6876 ms.
Time taken for inference per run is 29.634 ms.
Time taken for inference per run is 29.6831 ms.
Time taken for inference per run is 29.7009 ms.
Time taken for inference per run is 29.6777 ms.
Time taken for inference per run is 29.6679 ms.
Time taken for inference per run is 29.6568 ms.
Average time spent per iteration is 29.6766 ms.
Time taken for inference is 29.6568 ms.
 KeepCount 100

real	3m51.686s
user	0m38.148s
sys	1m49.428s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@48C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@52C thermal@46.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196282ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.1794 ms.
Time taken for inference per run is 26.251 ms.
Time taken for inference per run is 26.341 ms.
Time taken for inference per run is 26.197 ms.
Time taken for inference per run is 26.2535 ms.
Time taken for inference per run is 26.2875 ms.
Time taken for inference per run is 26.1707 ms.
Time taken for inference per run is 26.3307 ms.
Time taken for inference per run is 26.1593 ms.
Time taken for inference per run is 26.2874 ms.
Average time spent per iteration is 26.2457 ms.
Time taken for inference is 26.2874 ms.
 KeepCount 100

real	3m45.006s
user	0m38.664s
sys	1m49.192s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@43C PMIC@100C GPU@46.5C AO@53.5C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188821ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0666 ms.
Time taken for inference per run is 26.0716 ms.
Time taken for inference per run is 26.0676 ms.
Time taken for inference per run is 26.0742 ms.
Time taken for inference per run is 26.0681 ms.
Time taken for inference per run is 26.067 ms.
Time taken for inference per run is 26.0655 ms.
Time taken for inference per run is 26.0721 ms.
Time taken for inference per run is 26.0727 ms.
Time taken for inference per run is 26.0687 ms.
Average time spent per iteration is 26.0694 ms.
Time taken for inference is 26.0687 ms.
 KeepCount 100

real	3m37.328s
user	0m36.536s
sys	1m43.716s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@55C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 03:45:53 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 424/3965MB (lfb 815x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 249034ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 36.0569 ms.
Time taken for inference per run is 27.9684 ms.
Time taken for inference per run is 27.9927 ms.
Time taken for inference per run is 27.9593 ms.
Time taken for inference per run is 27.8786 ms.
Time taken for inference per run is 27.9006 ms.
Time taken for inference per run is 27.948 ms.
Time taken for inference per run is 27.8889 ms.
Time taken for inference per run is 28.0188 ms.
Time taken for inference per run is 27.9419 ms.
Average time spent per iteration is 28.7554 ms.
Time taken for inference is 27.9419 ms.
 KeepCount 100

real	4m42.360s
user	0m38.072s
sys	1m49.860s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 464x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@46.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 464x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 204910ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 36.4605 ms.
Time taken for inference per run is 36.5804 ms.
Time taken for inference per run is 36.4471 ms.
Time taken for inference per run is 36.4868 ms.
Time taken for inference per run is 36.575 ms.
Time taken for inference per run is 36.5359 ms.
Time taken for inference per run is 36.5435 ms.
Time taken for inference per run is 36.4738 ms.
Time taken for inference per run is 36.5635 ms.
Time taken for inference per run is 36.4438 ms.
Average time spent per iteration is 36.511 ms.
Time taken for inference is 36.4438 ms.
 KeepCount 100

real	4m3.949s
user	0m38.692s
sys	1m48.400s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 460x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 460x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@45.5C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196817ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3794 ms.
Time taken for inference per run is 26.2311 ms.
Time taken for inference per run is 26.2414 ms.
Time taken for inference per run is 26.2203 ms.
Time taken for inference per run is 26.3085 ms.
Time taken for inference per run is 26.2236 ms.
Time taken for inference per run is 26.3442 ms.
Time taken for inference per run is 26.3535 ms.
Time taken for inference per run is 26.3888 ms.
Time taken for inference per run is 26.3723 ms.
Average time spent per iteration is 26.3063 ms.
Time taken for inference is 26.3723 ms.
 KeepCount 100

real	3m45.698s
user	0m38.172s
sys	1m49.348s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 460x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49C iwlwifi@43C PMIC@100C GPU@48.5C AO@54.5C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 460x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@52.5C thermal@46.75C POM_5V_IN 2194/2194 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188732ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.077 ms.
Time taken for inference per run is 26.0725 ms.
Time taken for inference per run is 26.0732 ms.
Time taken for inference per run is 26.0673 ms.
Time taken for inference per run is 26.0643 ms.
Time taken for inference per run is 26.0715 ms.
Time taken for inference per run is 26.0688 ms.
Time taken for inference per run is 26.0687 ms.
Time taken for inference per run is 26.061 ms.
Time taken for inference per run is 26.0656 ms.
Average time spent per iteration is 26.069 ms.
Time taken for inference is 26.0656 ms.
 KeepCount 100

real	3m37.260s
user	0m36.076s
sys	1m44.264s
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 04:08:20 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 421/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247703ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 30.4247 ms.
Time taken for inference per run is 27.8672 ms.
Time taken for inference per run is 27.8688 ms.
Time taken for inference per run is 28.0037 ms.
Time taken for inference per run is 28.109 ms.
Time taken for inference per run is 27.9409 ms.
Time taken for inference per run is 27.8727 ms.
Time taken for inference per run is 27.9317 ms.
Time taken for inference per run is 27.9733 ms.
Time taken for inference per run is 27.9252 ms.
Average time spent per iteration is 28.1917 ms.
Time taken for inference is 27.9252 ms.
 KeepCount 100

real	4m40.549s
user	0m37.592s
sys	1m49.888s
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@46.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@45.5C AO@51C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 215508ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 46.8853 ms.
Time taken for inference per run is 46.8859 ms.
Time taken for inference per run is 46.744 ms.
Time taken for inference per run is 46.7365 ms.
Time taken for inference per run is 46.7815 ms.
Time taken for inference per run is 46.7185 ms.
Time taken for inference per run is 46.7725 ms.
Time taken for inference per run is 46.7932 ms.
Time taken for inference per run is 46.8005 ms.
Time taken for inference per run is 46.8589 ms.
Average time spent per iteration is 46.7977 ms.
Time taken for inference is 46.8589 ms.
 KeepCount 100

real	4m24.892s
user	0m38.160s
sys	1m49.496s
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@46C AO@52.5C thermal@46.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@45.5C iwlwifi@42C PMIC@100C GPU@45C AO@51C thermal@45.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196948ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2708 ms.
Time taken for inference per run is 26.3613 ms.
Time taken for inference per run is 26.2939 ms.
Time taken for inference per run is 26.3577 ms.
Time taken for inference per run is 26.3612 ms.
Time taken for inference per run is 26.1788 ms.
Time taken for inference per run is 26.2798 ms.
Time taken for inference per run is 26.244 ms.
Time taken for inference per run is 26.3329 ms.
Time taken for inference per run is 26.1647 ms.
Average time spent per iteration is 26.2845 ms.
Time taken for inference is 26.1647 ms.
 KeepCount 100

real	3m45.738s
user	0m38.456s
sys	1m49.272s
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@48.5C iwlwifi@42C PMIC@100C GPU@48C AO@55C thermal@48.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47C iwlwifi@42C PMIC@100C GPU@45.5C AO@52.5C thermal@46.75C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188649ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.06 ms.
Time taken for inference per run is 26.0709 ms.
Time taken for inference per run is 26.0649 ms.
Time taken for inference per run is 26.0643 ms.
Time taken for inference per run is 26.0611 ms.
Time taken for inference per run is 26.066 ms.
Time taken for inference per run is 26.0644 ms.
Time taken for inference per run is 26.0686 ms.
Time taken for inference per run is 26.0634 ms.
Time taken for inference per run is 26.0649 ms.
Average time spent per iteration is 26.0648 ms.
Time taken for inference is 26.0649 ms.
 KeepCount 100

real	3m37.142s
user	0m36.044s
sys	1m43.952s
+ timeout 2s tegrastats
RAM 878/3965MB (lfb 465x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 04:31:06 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 425/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247997ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.8138 ms.
Time taken for inference per run is 27.8851 ms.
Time taken for inference per run is 27.9073 ms.
Time taken for inference per run is 28.0277 ms.
Time taken for inference per run is 27.9909 ms.
Time taken for inference per run is 27.9119 ms.
Time taken for inference per run is 28.0591 ms.
Time taken for inference per run is 27.9871 ms.
Time taken for inference per run is 27.9216 ms.
Time taken for inference per run is 27.927 ms.
Average time spent per iteration is 28.0431 ms.
Time taken for inference is 27.927 ms.
 KeepCount 100

real	4m40.577s
user	0m38.652s
sys	1m49.484s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 479x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 479x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196006ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3334 ms.
Time taken for inference per run is 26.3821 ms.
Time taken for inference per run is 26.3149 ms.
Time taken for inference per run is 26.399 ms.
Time taken for inference per run is 26.2756 ms.
Time taken for inference per run is 26.3091 ms.
Time taken for inference per run is 26.3554 ms.
Time taken for inference per run is 26.3614 ms.
Time taken for inference per run is 26.308 ms.
Time taken for inference per run is 26.295 ms.
Average time spent per iteration is 26.3334 ms.
Time taken for inference is 26.295 ms.
 KeepCount 100

real	3m44.923s
user	0m38.172s
sys	1m49.648s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@48.5C iwlwifi@42C PMIC@100C GPU@48C AO@55C thermal@48.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47C iwlwifi@42C PMIC@100C GPU@48C AO@52.5C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196445ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3657 ms.
Time taken for inference per run is 26.4213 ms.
Time taken for inference per run is 26.1573 ms.
Time taken for inference per run is 26.1637 ms.
Time taken for inference per run is 26.1623 ms.
Time taken for inference per run is 26.402 ms.
Time taken for inference per run is 26.1744 ms.
Time taken for inference per run is 26.2542 ms.
Time taken for inference per run is 26.1735 ms.
Time taken for inference per run is 26.158 ms.
Average time spent per iteration is 26.2432 ms.
Time taken for inference is 26.158 ms.
 KeepCount 100

real	3m45.164s
user	0m38.232s
sys	1m49.724s
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@49C AO@55C thermal@49.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@47.5C iwlwifi@43C PMIC@100C GPU@47C AO@53.5C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188704ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0734 ms.
Time taken for inference per run is 26.0742 ms.
Time taken for inference per run is 26.0695 ms.
Time taken for inference per run is 26.0675 ms.
Time taken for inference per run is 26.0664 ms.
Time taken for inference per run is 26.0698 ms.
Time taken for inference per run is 26.071 ms.
Time taken for inference per run is 26.0681 ms.
Time taken for inference per run is 26.0693 ms.
Time taken for inference per run is 26.0665 ms.
Average time spent per iteration is 26.0696 ms.
Time taken for inference is 26.0665 ms.
 KeepCount 100

real	3m37.201s
user	0m35.832s
sys	1m44.188s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49.5C AO@56.5C thermal@50C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 04:53:11 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247029ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 31.1849 ms.
Time taken for inference per run is 27.9743 ms.
Time taken for inference per run is 27.9126 ms.
Time taken for inference per run is 27.8971 ms.
Time taken for inference per run is 27.9125 ms.
Time taken for inference per run is 27.8885 ms.
Time taken for inference per run is 27.9021 ms.
Time taken for inference per run is 27.9101 ms.
Time taken for inference per run is 27.8952 ms.
Time taken for inference per run is 27.8974 ms.
Average time spent per iteration is 28.2375 ms.
Time taken for inference is 27.8974 ms.
 KeepCount 100

real	4m39.746s
user	0m37.880s
sys	1m50.204s
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 208882ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 41.748 ms.
Time taken for inference per run is 41.6925 ms.
Time taken for inference per run is 41.6504 ms.
Time taken for inference per run is 41.5715 ms.
Time taken for inference per run is 41.6779 ms.
Time taken for inference per run is 41.6037 ms.
Time taken for inference per run is 41.706 ms.
Time taken for inference per run is 41.6097 ms.
Time taken for inference per run is 41.6397 ms.
Time taken for inference per run is 41.5924 ms.
Average time spent per iteration is 41.6492 ms.
Time taken for inference is 41.5924 ms.
 KeepCount 100

real	4m13.053s
user	0m37.780s
sys	1m49.320s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46C AO@52.5C thermal@47C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@45.5C AO@51C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195778ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3243 ms.
Time taken for inference per run is 26.2784 ms.
Time taken for inference per run is 26.1767 ms.
Time taken for inference per run is 26.1562 ms.
Time taken for inference per run is 26.3377 ms.
Time taken for inference per run is 26.2653 ms.
Time taken for inference per run is 26.2153 ms.
Time taken for inference per run is 26.2184 ms.
Time taken for inference per run is 26.2098 ms.
Time taken for inference per run is 26.2653 ms.
Average time spent per iteration is 26.2447 ms.
Time taken for inference is 26.2653 ms.
 KeepCount 100

real	3m44.528s
user	0m38.204s
sys	1m49.216s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49C iwlwifi@42C PMIC@100C GPU@48.5C AO@54.5C thermal@48.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 476x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46C AO@52.5C thermal@46.75C POM_5V_IN 2194/2194 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188639ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0747 ms.
Time taken for inference per run is 26.0722 ms.
Time taken for inference per run is 26.071 ms.
Time taken for inference per run is 26.0734 ms.
Time taken for inference per run is 26.0692 ms.
Time taken for inference per run is 26.068 ms.
Time taken for inference per run is 26.0696 ms.
Time taken for inference per run is 26.0747 ms.
Time taken for inference per run is 26.0709 ms.
Time taken for inference per run is 26.0724 ms.
Average time spent per iteration is 26.0716 ms.
Time taken for inference is 26.0724 ms.
 KeepCount 100

real	3m37.151s
user	0m36.424s
sys	1m43.576s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 468x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 05:15:43 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
+ echo performance
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
+ echo performance
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 424/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@45.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 247938ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 35.1898 ms.
Time taken for inference per run is 28.0416 ms.
Time taken for inference per run is 27.8761 ms.
Time taken for inference per run is 27.9363 ms.
Time taken for inference per run is 27.8895 ms.
Time taken for inference per run is 27.8962 ms.
Time taken for inference per run is 27.8768 ms.
Time taken for inference per run is 27.8779 ms.
Time taken for inference per run is 27.8749 ms.
Time taken for inference per run is 27.8958 ms.
Average time spent per iteration is 28.6355 ms.
Time taken for inference is 27.8958 ms.
 KeepCount 100

real	4m41.107s
user	0m38.336s
sys	1m50.332s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53.5C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 482x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 201369ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.1544 ms.
Time taken for inference per run is 33.1763 ms.
Time taken for inference per run is 33.1347 ms.
Time taken for inference per run is 33.1026 ms.
Time taken for inference per run is 33.035 ms.
Time taken for inference per run is 33.0262 ms.
Time taken for inference per run is 32.9918 ms.
Time taken for inference per run is 32.9962 ms.
Time taken for inference per run is 33.0226 ms.
Time taken for inference per run is 33.0763 ms.
Average time spent per iteration is 33.0716 ms.
Time taken for inference is 33.0763 ms.
 KeepCount 100

real	3m57.035s
user	0m38.080s
sys	1m49.176s
+ timeout 2s tegrastats
RAM 868/3965MB (lfb 481x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53.5C thermal@47.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 481x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46C AO@52C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196490ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.1906 ms.
Time taken for inference per run is 26.1858 ms.
Time taken for inference per run is 26.2155 ms.
Time taken for inference per run is 26.1806 ms.
Time taken for inference per run is 26.3338 ms.
Time taken for inference per run is 26.3766 ms.
Time taken for inference per run is 26.2461 ms.
Time taken for inference per run is 26.283 ms.
Time taken for inference per run is 26.2271 ms.
Time taken for inference per run is 26.1752 ms.
Average time spent per iteration is 26.2414 ms.
Time taken for inference is 26.1752 ms.
 KeepCount 100

real	3m45.256s
user	0m38.148s
sys	1m49.564s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 479x4MB) CPU [2%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 207/207
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 479x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@44C PMIC@100C GPU@46C AO@53C thermal@46.75C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188762ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0681 ms.
Time taken for inference per run is 26.0696 ms.
Time taken for inference per run is 26.0655 ms.
Time taken for inference per run is 26.0622 ms.
Time taken for inference per run is 26.0729 ms.
Time taken for inference per run is 26.0576 ms.
Time taken for inference per run is 26.0689 ms.
Time taken for inference per run is 26.0658 ms.
Time taken for inference per run is 26.0707 ms.
Time taken for inference per run is 26.0619 ms.
Average time spent per iteration is 26.0663 ms.
Time taken for inference is 26.0619 ms.
 KeepCount 100

real	3m37.269s
user	0m36.360s
sys	1m43.868s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49.5C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 05:38:01 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50C thermal@45.75C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 246766ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.1225 ms.
Time taken for inference per run is 27.898 ms.
Time taken for inference per run is 27.8659 ms.
Time taken for inference per run is 27.9287 ms.
Time taken for inference per run is 27.9359 ms.
Time taken for inference per run is 27.928 ms.
Time taken for inference per run is 27.9811 ms.
Time taken for inference per run is 27.9881 ms.
Time taken for inference per run is 27.884 ms.
Time taken for inference per run is 27.892 ms.
Average time spent per iteration is 28.0424 ms.
Time taken for inference is 27.892 ms.
 KeepCount 100

real	4m39.365s
user	0m38.000s
sys	1m49.644s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 480x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 480x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196395ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.0493 ms.
Time taken for inference per run is 27.8864 ms.
Time taken for inference per run is 27.9162 ms.
Time taken for inference per run is 27.9258 ms.
Time taken for inference per run is 27.9286 ms.
Time taken for inference per run is 28.0256 ms.
Time taken for inference per run is 27.9826 ms.
Time taken for inference per run is 27.9863 ms.
Time taken for inference per run is 27.9125 ms.
Time taken for inference per run is 27.9635 ms.
Average time spent per iteration is 27.9577 ms.
Time taken for inference is 27.9635 ms.
 KeepCount 100

real	3m46.933s
user	0m38.252s
sys	1m48.956s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@48C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@47C AO@52.5C thermal@47C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196538ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3273 ms.
Time taken for inference per run is 26.4052 ms.
Time taken for inference per run is 26.2719 ms.
Time taken for inference per run is 26.2145 ms.
Time taken for inference per run is 26.1862 ms.
Time taken for inference per run is 26.2108 ms.
Time taken for inference per run is 26.1989 ms.
Time taken for inference per run is 26.1655 ms.
Time taken for inference per run is 26.2263 ms.
Time taken for inference per run is 26.1598 ms.
Average time spent per iteration is 26.2366 ms.
Time taken for inference is 26.1598 ms.
 KeepCount 100

real	3m45.352s
user	0m37.892s
sys	1m49.812s
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 871/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46.5C AO@53C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188612ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0723 ms.
Time taken for inference per run is 26.0718 ms.
Time taken for inference per run is 26.0695 ms.
Time taken for inference per run is 26.0707 ms.
Time taken for inference per run is 26.0675 ms.
Time taken for inference per run is 26.0749 ms.
Time taken for inference per run is 26.0704 ms.
Time taken for inference per run is 26.0683 ms.
Time taken for inference per run is 26.0698 ms.
Time taken for inference per run is 26.0747 ms.
Average time spent per iteration is 26.071 ms.
Time taken for inference is 26.0747 ms.
 KeepCount 100

real	3m37.123s
user	0m36.076s
sys	1m43.996s
+ timeout 2s tegrastats
RAM 873/3965MB (lfb 478x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 06:00:07 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 422/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 124/124
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 248313ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 32.3317 ms.
Time taken for inference per run is 29.7348 ms.
Time taken for inference per run is 29.6212 ms.
Time taken for inference per run is 29.7051 ms.
Time taken for inference per run is 29.727 ms.
Time taken for inference per run is 29.6906 ms.
Time taken for inference per run is 29.7655 ms.
Time taken for inference per run is 29.6634 ms.
Time taken for inference per run is 29.6288 ms.
Time taken for inference per run is 29.7285 ms.
Average time spent per iteration is 29.9596 ms.
Time taken for inference is 29.7285 ms.
 KeepCount 100

real	4m42.792s
user	0m38.032s
sys	1m49.740s
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@48C iwlwifi@42C PMIC@100C GPU@46.5C AO@53.5C thermal@47.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 477x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 197568ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.047 ms.
Time taken for inference per run is 28.0122 ms.
Time taken for inference per run is 28.0161 ms.
Time taken for inference per run is 27.9371 ms.
Time taken for inference per run is 27.9703 ms.
Time taken for inference per run is 27.9659 ms.
Time taken for inference per run is 27.9705 ms.
Time taken for inference per run is 27.9573 ms.
Time taken for inference per run is 27.9624 ms.
Time taken for inference per run is 27.9638 ms.
Average time spent per iteration is 27.9803 ms.
Time taken for inference is 27.9638 ms.
 KeepCount 100

real	3m48.147s
user	0m38.040s
sys	1m49.524s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@42C PMIC@100C GPU@47.5C AO@54C thermal@48.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 475x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@47C AO@52C thermal@47C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196213ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.1888 ms.
Time taken for inference per run is 26.2791 ms.
Time taken for inference per run is 26.1832 ms.
Time taken for inference per run is 26.1901 ms.
Time taken for inference per run is 26.1958 ms.
Time taken for inference per run is 26.4386 ms.
Time taken for inference per run is 26.2891 ms.
Time taken for inference per run is 26.1979 ms.
Time taken for inference per run is 26.1919 ms.
Time taken for inference per run is 26.2015 ms.
Average time spent per iteration is 26.2356 ms.
Time taken for inference is 26.2015 ms.
 KeepCount 100

real	3m45.027s
user	0m38.320s
sys	1m49.356s
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
All clocks etc. set to max with jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
+ timeout 2s tegrastats
RAM 870/3965MB (lfb 473x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46.5C AO@53.5C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 189140ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0736 ms.
Time taken for inference per run is 26.0779 ms.
Time taken for inference per run is 26.0728 ms.
Time taken for inference per run is 26.0795 ms.
Time taken for inference per run is 26.0718 ms.
Time taken for inference per run is 26.0716 ms.
Time taken for inference per run is 26.0732 ms.
Time taken for inference per run is 26.0748 ms.
Time taken for inference per run is 26.0801 ms.
Time taken for inference per run is 26.0728 ms.
Average time spent per iteration is 26.0748 ms.
Time taken for inference is 26.0728 ms.
 KeepCount 100

real	3m37.663s
user	0m36.072s
sys	1m44.376s
+ timeout 2s tegrastats
RAM 872/3965MB (lfb 470x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 06:22:18 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 420/3965MB (lfb 811x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46C AO@50.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 243092ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 29.4407 ms.
Time taken for inference per run is 27.974 ms.
Time taken for inference per run is 27.8721 ms.
Time taken for inference per run is 27.9017 ms.
Time taken for inference per run is 27.888 ms.
Time taken for inference per run is 27.9776 ms.
Time taken for inference per run is 27.8813 ms.
Time taken for inference per run is 27.9118 ms.
Time taken for inference per run is 28.0004 ms.
Time taken for inference per run is 28.0821 ms.
Average time spent per iteration is 28.093 ms.
Time taken for inference is 28.0821 ms.
 KeepCount 100

real	4m35.783s
user	0m38.108s
sys	1m49.660s
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44.5C CPU@47.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@53C thermal@47.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@41C PMIC@100C GPU@46.5C AO@51C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195981ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3167 ms.
Time taken for inference per run is 26.3697 ms.
Time taken for inference per run is 26.3303 ms.
Time taken for inference per run is 26.3337 ms.
Time taken for inference per run is 26.3194 ms.
Time taken for inference per run is 26.2169 ms.
Time taken for inference per run is 26.2069 ms.
Time taken for inference per run is 26.1927 ms.
Time taken for inference per run is 26.1868 ms.
Time taken for inference per run is 26.1996 ms.
Average time spent per iteration is 26.2673 ms.
Time taken for inference is 26.1996 ms.
 KeepCount 100

real	3m44.761s
user	0m38.124s
sys	1m49.508s
+ timeout 2s tegrastats
RAM 913/3965MB (lfb 456x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46C CPU@49.5C iwlwifi@42C PMIC@100C GPU@48C AO@54.5C thermal@49.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
+ echo 921600000
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 456x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@48C AO@53C thermal@47.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196506ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2198 ms.
Time taken for inference per run is 26.1945 ms.
Time taken for inference per run is 26.1866 ms.
Time taken for inference per run is 26.1958 ms.
Time taken for inference per run is 26.1906 ms.
Time taken for inference per run is 26.3998 ms.
Time taken for inference per run is 26.1934 ms.
Time taken for inference per run is 26.1788 ms.
Time taken for inference per run is 26.2609 ms.
Time taken for inference per run is 26.2153 ms.
Average time spent per iteration is 26.2235 ms.
Time taken for inference is 26.2153 ms.
 KeepCount 100

real	3m45.236s
user	0m38.376s
sys	1m49.572s
+ timeout 2s tegrastats
RAM 914/3965MB (lfb 460x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@49.5C iwlwifi@43C PMIC@100C GPU@49C AO@55.5C thermal@49.5C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 460x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48C iwlwifi@43C PMIC@100C GPU@46.5C AO@53C thermal@47.25C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188794ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0631 ms.
Time taken for inference per run is 26.0683 ms.
Time taken for inference per run is 26.0672 ms.
Time taken for inference per run is 26.0708 ms.
Time taken for inference per run is 26.0635 ms.
Time taken for inference per run is 26.0563 ms.
Time taken for inference per run is 26.0638 ms.
Time taken for inference per run is 26.0617 ms.
Time taken for inference per run is 26.0658 ms.
Time taken for inference per run is 26.0632 ms.
Average time spent per iteration is 26.0644 ms.
Time taken for inference is 26.0632 ms.
 KeepCount 100

real	3m37.292s
user	0m36.844s
sys	1m43.344s
+ timeout 2s tegrastats
RAM 915/3965MB (lfb 458x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50.5C iwlwifi@43C PMIC@100C GPU@49C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 06:44:18 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
+ echo performance
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 428/3965MB (lfb 758x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43C CPU@46C iwlwifi@43C PMIC@100C GPU@47C AO@51C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 254937ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 28.7533 ms.
Time taken for inference per run is 27.9517 ms.
Time taken for inference per run is 27.916 ms.
Time taken for inference per run is 28.0571 ms.
Time taken for inference per run is 27.8822 ms.
Time taken for inference per run is 27.9807 ms.
Time taken for inference per run is 27.988 ms.
Time taken for inference per run is 27.9714 ms.
Time taken for inference per run is 28.1004 ms.
Time taken for inference per run is 27.8785 ms.
Average time spent per iteration is 28.0479 ms.
Time taken for inference is 27.8785 ms.
 KeepCount 100

real	4m47.488s
user	0m39.312s
sys	1m50.252s
+ timeout 2s tegrastats
RAM 894/3965MB (lfb 312x4MB) CPU [1%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@49C iwlwifi@43C PMIC@100C GPU@47.5C AO@54.5C thermal@48C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
+ echo 'CPUs and GPU set to performance'
CPUs and GPU set to performance
+ timeout 2s tegrastats
RAM 893/3965MB (lfb 312x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@47C AO@52.5C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 201590ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.0884 ms.
Time taken for inference per run is 33.1147 ms.
Time taken for inference per run is 33.1514 ms.
Time taken for inference per run is 33.0709 ms.
Time taken for inference per run is 33.1443 ms.
Time taken for inference per run is 33.1119 ms.
Time taken for inference per run is 33.1107 ms.
Time taken for inference per run is 33.0848 ms.
Time taken for inference per run is 33.0804 ms.
Time taken for inference per run is 33.1082 ms.
Average time spent per iteration is 33.1066 ms.
Time taken for inference is 33.1082 ms.
 KeepCount 100

real	3m57.193s
user	0m38.308s
sys	1m49.368s
+ timeout 2s tegrastats
RAM 893/3965MB (lfb 309x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45.5C CPU@48.5C iwlwifi@43C PMIC@100C GPU@47.5C AO@54C thermal@48.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 893/3965MB (lfb 309x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@44C CPU@47C iwlwifi@42C PMIC@100C GPU@46.5C AO@52C thermal@46.75C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 196842ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.3144 ms.
Time taken for inference per run is 26.3881 ms.
Time taken for inference per run is 26.2767 ms.
Time taken for inference per run is 26.253 ms.
Time taken for inference per run is 26.164 ms.
Time taken for inference per run is 26.2491 ms.
Time taken for inference per run is 26.1672 ms.
Time taken for inference per run is 26.2126 ms.
Time taken for inference per run is 26.1618 ms.
Time taken for inference per run is 26.2264 ms.
Average time spent per iteration is 26.2413 ms.
Time taken for inference is 26.2264 ms.
 KeepCount 100

real	3m45.665s
user	0m38.832s
sys	1m49.300s
+ timeout 2s tegrastats
RAM 894/3965MB (lfb 307x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@54.5C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 894/3965MB (lfb 308x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@43C PMIC@100C GPU@46C AO@53C thermal@47C POM_5V_IN 2191/2191 POM_5V_GPU 206/206 POM_5V_CPU 372/372
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 189236ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0711 ms.
Time taken for inference per run is 26.074 ms.
Time taken for inference per run is 26.0675 ms.
Time taken for inference per run is 26.0669 ms.
Time taken for inference per run is 26.0659 ms.
Time taken for inference per run is 26.0732 ms.
Time taken for inference per run is 26.0664 ms.
Time taken for inference per run is 26.0708 ms.
Time taken for inference per run is 26.0693 ms.
Time taken for inference per run is 26.0733 ms.
Average time spent per iteration is 26.0698 ms.
Time taken for inference is 26.0733 ms.
 KeepCount 100

real	3m37.743s
user	0m36.544s
sys	1m44.056s
+ timeout 2s tegrastats
RAM 896/3965MB (lfb 305x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47.5C CPU@50.5C iwlwifi@43C PMIC@100C GPU@48.5C AO@56C thermal@49.75C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
Fri Jul  5 07:06:43 CEST 2019
+ cd /usr/src/tensorrt/bin
+ cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
schedutil
schedutil
schedutil
schedutil
+ cat /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor
performance
+ for gov in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
+ echo performance
+ sudo tee -a /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor
performance
+ echo 'CPUs set to performance'
CPUs set to performance
+ timeout 2s tegrastats
RAM 420/3965MB (lfb 812x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@42.5C CPU@45.5C iwlwifi@42C PMIC@100C GPU@46.5C AO@50.5C thermal@46.25C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 250042ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.8631 ms.
Time taken for inference per run is 27.8894 ms.
Time taken for inference per run is 27.8718 ms.
Time taken for inference per run is 27.8721 ms.
Time taken for inference per run is 27.9812 ms.
Time taken for inference per run is 27.889 ms.
Time taken for inference per run is 27.8701 ms.
Time taken for inference per run is 27.871 ms.
Time taken for inference per run is 27.9415 ms.
Time taken for inference per run is 27.8698 ms.
Average time spent per iteration is 28.4919 ms.
Time taken for inference is 27.8698 ms.
 KeepCount 100

real	4m43.113s
user	0m38.220s
sys	1m49.596s
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 474x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@47.5C iwlwifi@42C PMIC@100C GPU@47C AO@53C thermal@47.25C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ echo performance
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
performance
CPUs and GPU set to performance
+ echo 'CPUs and GPU set to performance'
+ timeout 2s tegrastats
RAM 865/3965MB (lfb 474x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 201564ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 33.0893 ms.
Time taken for inference per run is 33.0432 ms.
Time taken for inference per run is 33 ms.
Time taken for inference per run is 33.0159 ms.
Time taken for inference per run is 33.0283 ms.
Time taken for inference per run is 32.9972 ms.
Time taken for inference per run is 33.0423 ms.
Time taken for inference per run is 32.9986 ms.
Time taken for inference per run is 33.0457 ms.
Time taken for inference per run is 33.0331 ms.
Average time spent per iteration is 33.0294 ms.
Time taken for inference is 33.0331 ms.
 KeepCount 100

real	3m57.183s
user	0m38.228s
sys	1m49.224s
+ timeout 2s tegrastats
RAM 866/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@42C PMIC@100C GPU@47C AO@53.5C thermal@48C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 165/165
+ sleep 60
+ echo nvhost_podgov
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/governor
nvhost_podgov
+ echo 921600000
+ sudo tee -a /sys/devices/57000000.gpu/devfreq/57000000.gpu/min_freq
921600000
CPUs set to performance, GPU governor set to normal and GPU min_freq set to max
+ echo 'CPUs set to performance, GPU governor set to normal and GPU min_freq set to max'
+ timeout 2s tegrastats
RAM 867/3965MB (lfb 471x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@43.5C CPU@46.5C iwlwifi@42C PMIC@100C GPU@46C AO@51.5C thermal@46.5C POM_5V_IN 1702/1702 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 195950ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.2216 ms.
Time taken for inference per run is 26.3338 ms.
Time taken for inference per run is 26.3757 ms.
Time taken for inference per run is 26.2869 ms.
Time taken for inference per run is 26.2026 ms.
Time taken for inference per run is 26.2025 ms.
Time taken for inference per run is 26.2054 ms.
Time taken for inference per run is 26.1878 ms.
Time taken for inference per run is 26.204 ms.
Time taken for inference per run is 26.2597 ms.
Average time spent per iteration is 26.248 ms.
Time taken for inference is 26.2597 ms.
 KeepCount 100

real	3m44.767s
user	0m38.572s
sys	1m49.032s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@46.5C CPU@49.5C iwlwifi@42C PMIC@100C GPU@48.5C AO@55C thermal@49C POM_5V_IN 1744/1744 POM_5V_GPU 0/0 POM_5V_CPU 166/166
+ sleep 60
+ sudo jetson_clocks
+ echo 'All clocks etc. set to max with jetson_clocks'
All clocks etc. set to max with jetson_clocks
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 469x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@45C CPU@48C iwlwifi@42C PMIC@100C GPU@46C AO@53C thermal@46.75C POM_5V_IN 2191/2191 POM_5V_GPU 165/165 POM_5V_CPU 413/413
+ sudo ./sample_uff_ssd_rect
../data/ssd/sample_unpruned_mobilenet_v2.uff
Registering UFF model
Registered Input
Registered output NMS
Creating engine
Begin parsing model...
End parsing model...
Begin building engine...
Time lapsed to create an engine: 188563ms
End building engine...
Created engine
 Num batches  1
 Data Size  270000
*** deserializing
3 Binding
Allocating buffer sizes for binding index: 0 of size : 270000 * 4 B
Allocating buffer sizes for binding index: 1 of size : 700 * 4 B
Allocating buffer sizes for binding index: 2 of size : 1 * 4 B
Time taken for inference per run is 26.0733 ms.
Time taken for inference per run is 26.0731 ms.
Time taken for inference per run is 26.0696 ms.
Time taken for inference per run is 26.0818 ms.
Time taken for inference per run is 26.0727 ms.
Time taken for inference per run is 26.0748 ms.
Time taken for inference per run is 26.07 ms.
Time taken for inference per run is 26.076 ms.
Time taken for inference per run is 26.0709 ms.
Time taken for inference per run is 26.0733 ms.
Average time spent per iteration is 26.0736 ms.
Time taken for inference is 26.0733 ms.
 KeepCount 100

real	3m37.073s
user	0m35.688s
sys	1m44.288s
+ timeout 2s tegrastats
RAM 869/3965MB (lfb 467x4MB) CPU [0%@1428,0%@1428,0%@1428,0%@1428] EMC_FREQ 0% GR3D_FREQ 0% PLL@47C CPU@50C iwlwifi@43C PMIC@100C GPU@48.5C AO@55.5C thermal@49.25C POM_5V_IN 2232/2232 POM_5V_GPU 206/206 POM_5V_CPU 413/413
+ sleep 60
+ sudo reboot now
Connection to jetsonnano.local closed by remote host.
^C
localhost(~): exit

Script done on Fri Jul  5 07:27:47 2019
